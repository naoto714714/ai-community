"""Gemini APIçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«."""

import asyncio
import logging
import os
import re
import threading
from pathlib import Path

import google.generativeai as genai  # type: ignore
from google.generativeai.types import GenerateContentResponse  # type: ignore
from sqlalchemy.orm import Session

# å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚ã®é™çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from .. import crud
except ImportError:
    import crud

logger = logging.getLogger(__name__)


class GeminiAPIClient:
    """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ."""

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¸€å…ƒç®¡ç†
    FALLBACK_MESSAGE = "é€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸğŸ˜… ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼"

    # AI IDå®šæ•°
    AI_HARUTO_ID = "ai_haruto"

    def __init__(self) -> None:
        """åˆæœŸåŒ–."""
        logger.info("GeminiAPIClientåˆæœŸåŒ–é–‹å§‹")
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            logger.error("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            raise ValueError("GEMINI_API_KEY environment variable is required")

        logger.info("GEMINI_API_KEYç¢ºèªæ¸ˆã¿")
        genai.configure(api_key=self.api_key)  # type: ignore
        self.model = genai.GenerativeModel("gemini-2.5-flash-preview-05-20")  # type: ignore
        logger.info("Gemini 2.5 Flash Preview 05-20ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        self._system_prompt: str | None = None
        self._load_system_prompt()

    def _load_system_prompt(self) -> None:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€."""
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰åŸºæœ¬ãƒ‘ã‚¹ã‚’å–å¾—
        base_path = os.getenv("AI_COMMUNITY_BASE_PATH")
        if not base_path:
            # ã‚ˆã‚Šå®‰å…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ¤œç´¢
            current = Path(__file__).parent
            while current != current.parent:
                prompt_dir = current / "prompts"
                if prompt_dir.exists():
                    base_path = str(current)
                    break
                current = current.parent

            if not base_path:
                logger.error("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                raise FileNotFoundError("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®ç‰¹å®šã«å¤±æ•—ã—ã¾ã—ãŸ")

        prompt_path = Path(base_path) / "prompts" / "001_ãƒãƒ«ãƒˆ.md"

        logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿è©¦è¡Œ: {prompt_path}")
        try:
            with open(prompt_path, encoding="utf-8") as f:
                self._system_prompt = f.read()
            logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: æ–‡å­—æ•°={len(self._system_prompt)}")
        except FileNotFoundError:
            logger.warning(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prompt_path}ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨")
            self._system_prompt = """
ã‚ãªãŸã¯ã€Œãƒãƒ«ãƒˆã€ã¨ã„ã†åå‰ã®æ˜ã‚‹ãè¦ªã—ã¿ã‚„ã™ã„ç”·æ€§ã§ã™ã€‚
å¤ªé™½ã®ã‚ˆã†ã«æ¸©ã‹ãã€äººã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¤§åˆ‡ã«ã™ã‚‹æ€§æ ¼ã§ã™ã€‚
è¦ªã—ã¿ã‚„ã™ãã€ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå£èª¿ã§è©±ã—ã¦ãã ã•ã„ã€‚
"""

    def _format_conversation_history(self, messages: list) -> str:
        """éå»ã®ä¼šè©±å±¥æ­´ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹"""
        if not messages:
            return ""

        history_lines = ["===== éå»ã®ä¼šè©±å±¥æ­´ ====="]
        for msg in messages:
            # user_typeã‚’ä½¿ã£ã¦AIã‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚’åˆ¤å®š
            if hasattr(msg, "user_type") and msg.user_type == "ai":
                # AIã®å ´åˆã¯ã€ã©ã®AIã‹ã‚’æ˜ç¢ºã«ã™ã‚‹
                if msg.user_id == self.AI_HARUTO_ID:
                    history_lines.append(f"[AI:ãƒãƒ«ãƒˆ]: {msg.content}")
                else:
                    # ä»–ã®AIã®å ´åˆï¼ˆå°†æ¥å¯¾å¿œï¼‰
                    history_lines.append(f"[AI:{msg.user_name}]: {msg.content}")
            else:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ´åˆ
                history_lines.append(f"[ãƒ¦ãƒ¼ã‚¶ãƒ¼:{msg.user_name}]: {msg.content}")

        history_lines.append("")  # ç©ºè¡Œã‚’è¿½åŠ 
        return "\n".join(history_lines)

    async def _fetch_conversation_history(self, channel_id: str, db_session: Session) -> str:
        """ä¼šè©±å±¥æ­´ã‚’å–å¾—ã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹"""
        try:
            recent_messages = crud.get_recent_channel_messages(db_session, channel_id, limit=30)
            logger.debug(f"ãƒ‡ãƒãƒƒã‚°: å–å¾—ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°={len(recent_messages)}")
            for i, msg in enumerate(recent_messages[-5:]):  # æœ€æ–°5ä»¶ã‚’ãƒ­ã‚°å‡ºåŠ›
                logger.debug(f"ãƒ‡ãƒãƒƒã‚°: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i}: user_id={msg.user_id}, content='{msg.content[:30]}...'")
            conversation_history = self._format_conversation_history(recent_messages)
            logger.info(f"éå»ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—: {len(recent_messages)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
            logger.debug(f"ãƒ‡ãƒãƒƒã‚°: conversation_history ã®é•·ã•={len(conversation_history)}")
            return conversation_history
        except Exception as e:
            logger.error(f"éå»ã®ä¼šè©±å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback

            logger.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {traceback.format_exc()}")
            return ""

    def _build_prompt(self, user_message: str, conversation_history: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"""
        if conversation_history:
            return f"{self._system_prompt}\n\n{conversation_history}===== ç¾åœ¨ã®è³ªå• =====\n[ãƒ¦ãƒ¼ã‚¶ãƒ¼]: {user_message}\n[AI:ãƒãƒ«ãƒˆ]:"
        return f"{self._system_prompt}\n\n[ãƒ¦ãƒ¼ã‚¶ãƒ¼]: {user_message}\n[AI:ãƒãƒ«ãƒˆ]:"

    async def generate_response(
        self, user_message: str, channel_id: str | None = None, db_session: Session | None = None, max_retries: int = 5
    ) -> str:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹.

        Args:
            user_message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            channel_id: ãƒãƒ£ãƒ³ãƒãƒ«IDï¼ˆéå»ã®ä¼šè©±å±¥æ­´å–å¾—ç”¨ï¼‰
            db_session: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
            max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°

        Returns:
            AIã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
        """
        logger.info(f"Gemini APIå¿œç­”ç”Ÿæˆé–‹å§‹: user_message='{user_message[:50]}...' max_retries={max_retries}")

        # éå»ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
        conversation_history = ""
        logger.debug(f"ãƒ‡ãƒãƒƒã‚°: channel_id={channel_id}, db_session={db_session is not None}")
        if channel_id and db_session:
            conversation_history = await self._fetch_conversation_history(channel_id, db_session)
        else:
            logger.debug(
                f"ãƒ‡ãƒãƒƒã‚°: ä¼šè©±å±¥æ­´å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ— - channel_id={channel_id}, db_session={db_session is not None}"
            )

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        prompt = self._build_prompt(user_message, conversation_history)
        if conversation_history:
            logger.debug("ãƒ‡ãƒãƒƒã‚°: ä¼šè©±å±¥æ­´ä»˜ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨")
        else:
            logger.debug("ãƒ‡ãƒãƒƒã‚°: ä¼šè©±å±¥æ­´ãªã—ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸€éƒ¨ã‚’ãƒ­ã‚°ã«å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ã€æœ¬ç•ªã§ã¯å‡ºåŠ›ã•ã‚Œãªã„ï¼‰
        logger.debug(f"ãƒ‡ãƒãƒƒã‚°: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·={len(prompt)}")
        if len(prompt) > 2000:
            logger.debug(f"ãƒ‡ãƒãƒƒã‚°: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…ˆé ­1000æ–‡å­—: {prompt[:1000]}...")
        else:
            logger.debug(f"ãƒ‡ãƒãƒƒã‚°: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨ä½“: {prompt}")

        for attempt in range(max_retries):
            try:
                logger.info(f"Gemini APIå‘¼ã³å‡ºã—è©¦è¡Œ {attempt + 1}/{max_retries}")
                # éåŒæœŸã§Gemini APIã‚’å‘¼ã³å‡ºã—
                loop = asyncio.get_event_loop()
                response: GenerateContentResponse = await loop.run_in_executor(None, self._sync_generate, prompt)

                if response.text:
                    response_text = response.text.strip()
                    logger.info(f"Gemini APIå¿œç­”æˆåŠŸ: response_length={len(response_text)}")
                    return response_text

                logger.warning("Gemini APIã‹ã‚‰ç©ºã®å¿œç­”ã‚’å—ä¿¡")
                raise Exception("Empty response from Gemini API")

            except Exception as e:
                # ã‚ˆã‚Šå…·ä½“çš„ãªä¾‹å¤–å‡¦ç†
                error_type = type(e).__name__
                logger.error(f"Gemini APIå‘¼ã³å‡ºã—å¤±æ•— (è©¦è¡Œ {attempt + 1}/{max_retries}): {error_type}: {str(e)}")

                # ç‰¹å®šã®ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã«å¯¾ã™ã‚‹å‡¦ç†ãŒå¿…è¦ãªå ´åˆ
                # if isinstance(e, SpecificAPIError):
                #     # ç‰¹åˆ¥ãªå‡¦ç†

                if attempt == max_retries - 1:
                    # æœ€å¾Œã®ãƒªãƒˆãƒ©ã‚¤ã§ã‚‚å¤±æ•—ã—ãŸå ´åˆ
                    logger.error("Gemini API: å…¨ãƒªãƒˆãƒ©ã‚¤è©¦è¡ŒãŒå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’è¿”ã™")
                    return self.FALLBACK_MESSAGE

                # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
                wait_time = 2**attempt
                logger.info(f"Gemini API: {wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
                await asyncio.sleep(wait_time)
                continue

        return self.FALLBACK_MESSAGE

    def _sync_generate(self, prompt: str) -> GenerateContentResponse:
        """
        åŒæœŸçš„ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆrun_in_executorç”¨ï¼‰.

        Gemini 2.5 Flash Preview 05-20ç”¨ã®åŸºæœ¬è¨­å®šã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
        """
        # Gemini 2.5 Flashç”¨ã®åŸºæœ¬è¨­å®š
        generation_config = {
            "temperature": 0.7,
            "max_output_tokens": 1000,
        }

        return self.model.generate_content(prompt, generation_config=generation_config)  # type: ignore

    def should_respond_to_message(self, message: str) -> bool:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¿œç­”ã™ã¹ãã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹.

        Args:
            message: ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

        Returns:
            å¿œç­”ã™ã¹ãå ´åˆTrue
        """
        # æ—¥æœ¬èªç’°å¢ƒã«å¯¾å¿œã—ãŸ@AIæ¤œå‡ºï¼ˆå…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚‚è€ƒæ…®ï¼‰
        # (?:^|[\sã€€]) - æ–‡é ­ã¾ãŸã¯åŠè§’ãƒ»å…¨è§’ç©ºç™½æ–‡å­—ã®å¾Œ
        # @ai - @aiã®ãƒªãƒ†ãƒ©ãƒ«ï¼ˆå¤§æ–‡å­—å°æ–‡å­—åŒºåˆ¥ãªã—ï¼‰
        # (?=[\sã€€]|$) - åŠè§’ãƒ»å…¨è§’ç©ºç™½æ–‡å­—ã¾ãŸã¯æ–‡æœ«ã®å‰
        pattern = r"(?:^|[\sã€€])@ai(?=[\sã€€]|$)"
        result = bool(re.search(pattern, message.lower()))
        logger.debug(f"@AIæ¤œå‡º: '{message[:50]}...' -> {result}")
        return result


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
gemini_client: GeminiAPIClient | None = None
_lock = threading.Lock()


def get_gemini_client() -> GeminiAPIClient:
    """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—."""
    global gemini_client
    if gemini_client is None:
        with _lock:
            # ãƒ€ãƒ–ãƒ«ãƒã‚§ãƒƒã‚¯ãƒ­ãƒƒã‚­ãƒ³ã‚°
            if gemini_client is None:
                logger.info("æ–°ã—ã„GeminiAPIClientã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ")
                gemini_client = GeminiAPIClient()
    return gemini_client
