"""Gemini APIçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«."""

import asyncio
import logging
import os
import re
import sys
import threading
from pathlib import Path

# å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚ã®é™çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦å®Ÿè¡Œã•ã‚Œã‚‹å ´åˆ
    from .. import crud
    from ..constants.ai_config import DEFAULT_CONVERSATION_HISTORY_LIMIT, DEFAULT_MAX_OUTPUT_TOKENS
    from .personality_manager import AIPersonality, get_personality_manager
except ImportError:
    # ç›´æ¥å®Ÿè¡Œã•ã‚Œã‚‹å ´åˆ
    import crud
    from ai.personality_manager import AIPersonality, get_personality_manager
    from constants.ai_config import DEFAULT_CONVERSATION_HISTORY_LIMIT, DEFAULT_MAX_OUTPUT_TOKENS
from google import genai  # type: ignore
from google.genai import types  # type: ignore
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)


class GeminiAPIClient:
    """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ."""

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¸€å…ƒç®¡ç†
    FALLBACK_MESSAGE = "é€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸğŸ˜… ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼"

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯äººæ ¼ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨ï¼‰
    FALLBACK_AI_NAME = "ã‚·ã‚¹ãƒ†ãƒ "
    FALLBACK_AI_ID = "ai_system"

    def __init__(self) -> None:
        """åˆæœŸåŒ–."""
        logger.info("GeminiAPIClientåˆæœŸåŒ–é–‹å§‹")
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            logger.error("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            raise ValueError("GEMINI_API_KEY environment variable is required")

        logger.info("GEMINI_API_KEYç¢ºèªæ¸ˆã¿")
        self.client = genai.Client(api_key=self.api_key)  # type: ignore
        logger.info("Gemini 2.5 Flash Preview 05-20ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
        self.personality_manager = get_personality_manager()

        # ã‚·ã‚¹ãƒ†ãƒ äººæ ¼ã‚’ä½œæˆ
        self.system_personality = AIPersonality(
            file_name="system",
            name=self.FALLBACK_AI_NAME,
            prompt_content="ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
            user_id=self.FALLBACK_AI_ID,
        )
        self._fallback_prompt: str | None = None
        self._load_fallback_prompt()

    def _load_fallback_prompt(self) -> None:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€."""
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰åŸºæœ¬ãƒ‘ã‚¹ã‚’å–å¾—
        base_path = os.getenv("AI_COMMUNITY_BASE_PATH")
        if not base_path:
            # ã‚ˆã‚Šå®‰å…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ¤œç´¢
            current = Path(__file__).parent
            while current != current.parent:
                prompt_dir = current / "prompts"
                if prompt_dir.exists():
                    base_path = str(current)
                    break
                current = current.parent

            if not base_path:
                logger.error("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                raise FileNotFoundError("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®ç‰¹å®šã«å¤±æ•—ã—ã¾ã—ãŸ")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š
        self._fallback_prompt = """
ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¼šè©±ã‚’æ¥½ã—ã¿ã€å½¹ã«ç«‹ã¤æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚
"""
        logger.info("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š")

    def _select_random_personality(self, exclude_user_id: str | None = None) -> AIPersonality:
        """ãƒ©ãƒ³ãƒ€ãƒ ã«äººæ ¼ã‚’é¸æŠã—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ç®¡ç†.

        Args:
            exclude_user_id: é™¤å¤–ã™ã‚‹AIäººæ ¼ã®user_idï¼ˆé€£ç¶šç™ºè¨€é˜²æ­¢ç”¨ï¼‰

        Returns:
            é¸æŠã•ã‚ŒãŸäººæ ¼

        """
        try:
            # ãƒ©ãƒ³ãƒ€ãƒ ã«äººæ ¼ã‚’é¸æŠï¼ˆé™¤å¤–å¯¾è±¡è€ƒæ…®ï¼‰
            personality = self.personality_manager.get_random_personality(exclude_user_id)
            if personality:
                if exclude_user_id:
                    logger.info(
                        f"é€£ç¶šç™ºè¨€é˜²æ­¢è€ƒæ…®ã§ãƒ©ãƒ³ãƒ€ãƒ äººæ ¼é¸æŠ: {personality.name} (user_id: {personality.user_id}), é™¤å¤–å¯¾è±¡: {exclude_user_id}"
                    )
                else:
                    logger.debug(f"ãƒ©ãƒ³ãƒ€ãƒ äººæ ¼é¸æŠ: {personality.name} (user_id: {personality.user_id})")
                return personality
        except Exception as e:
            logger.error(f"äººæ ¼é¸æŠã‚¨ãƒ©ãƒ¼: {e!s}")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯äººæ ¼ã‚’è¿”ã™
        logger.warning("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯äººæ ¼ã‚’ä½¿ç”¨")
        return AIPersonality(
            file_name="fallback.md",
            name=self.FALLBACK_AI_NAME,
            prompt_content=self._fallback_prompt or "è¦ªã—ã¿ã‚„ã™ã„AIã§ã™ã€‚",
            user_id=self.FALLBACK_AI_ID,
        )

    def _format_conversation_history(self, messages: list) -> str:
        """éå»ã®ä¼šè©±å±¥æ­´ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹"""
        if not messages:
            return ""

        history_lines = ["===== éå»ã®ä¼šè©±å±¥æ­´ ====="]
        for msg in messages:
            # AIã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åŒºåˆ¥ãªãã€åå‰ã®ã¿ã§è¡¨ç¤º
            history_lines.append(f"{msg.user_name}: {msg.content}")

        history_lines.append("")  # ç©ºè¡Œã‚’è¿½åŠ 
        return "\n".join(history_lines)

    async def _fetch_conversation_history(self, channel_id: str, db_session: Session) -> str:
        """ä¼šè©±å±¥æ­´ã‚’å–å¾—ã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹"""
        try:
            recent_messages = crud.get_recent_channel_messages(
                db_session, channel_id, limit=DEFAULT_CONVERSATION_HISTORY_LIMIT
            )
            logger.debug(f"ãƒ‡ãƒãƒƒã‚°: å–å¾—ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°={len(recent_messages)}")
            for i, msg in enumerate(recent_messages[-5:]):  # æœ€æ–°5ä»¶ã‚’ãƒ­ã‚°å‡ºåŠ›
                logger.debug(f"ãƒ‡ãƒãƒƒã‚°: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i}: user_id={msg.user_id}, content='{msg.content[:30]}...'")
            conversation_history = self._format_conversation_history(recent_messages)
            logger.info(f"éå»ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—: {len(recent_messages)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
            logger.debug(f"ãƒ‡ãƒãƒƒã‚°: conversation_history ã®é•·ã•={len(conversation_history)}")
            return conversation_history
        except Exception as e:
            logger.error(f"éå»ã®ä¼šè©±å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e!s}")
            import traceback

            logger.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {traceback.format_exc()}")
            return ""

    async def generate_response(
        self,
        user_message: str,
        channel_id: str | None = None,
        db_session: Session | None = None,
        max_retries: int = 5,
        exclude_user_id: str | None = None,
    ) -> tuple[str, AIPersonality]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹.

        Args:
            user_message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            channel_id: ãƒãƒ£ãƒ³ãƒãƒ«IDï¼ˆéå»ã®ä¼šè©±å±¥æ­´å–å¾—ç”¨ï¼‰
            db_session: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
            max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
            exclude_user_id: é™¤å¤–ã™ã‚‹AIäººæ ¼ã®user_idï¼ˆé€£ç¶šç™ºè¨€é˜²æ­¢ç”¨ï¼‰

        Returns:
            tuple[AIã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ, é¸æŠã•ã‚ŒãŸäººæ ¼]

        """
        logger.info(f"Gemini APIå¿œç­”ç”Ÿæˆé–‹å§‹: user_message='{user_message[:50]}...' max_retries={max_retries}")

        # ãƒ©ãƒ³ãƒ€ãƒ ã«äººæ ¼ã‚’é¸æŠï¼ˆé€£ç¶šç™ºè¨€é˜²æ­¢è€ƒæ…®ï¼‰
        personality = self._select_random_personality(exclude_user_id)
        logger.info(f"é¸æŠã•ã‚ŒãŸäººæ ¼: {personality.name}")

        # éå»ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—
        conversation_history = ""
        logger.debug(f"ãƒ‡ãƒãƒƒã‚°: channel_id={channel_id}, db_session={db_session is not None}")
        if channel_id and db_session:
            conversation_history = await self._fetch_conversation_history(channel_id, db_session)
        else:
            logger.debug(
                f"ãƒ‡ãƒãƒƒã‚°: ä¼šè©±å±¥æ­´å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ— - channel_id={channel_id}, db_session={db_session is not None}"
            )

        # æ–°ã—ã„APIã§ã¯system_instructionã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
        logger.debug(f"é¸æŠã•ã‚ŒãŸäººæ ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(personality.prompt_content)}")
        if conversation_history:
            logger.debug(f"ä¼šè©±å±¥æ­´é•·: {len(conversation_history)}")
            # ä¼šè©±å±¥æ­´ãŒã‚ã‚‹å ´åˆã¯æ–‡è„ˆã‚‚å«ã‚ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
            enhanced_message = f"{conversation_history}\n\nç¾åœ¨ã®è³ªå•: {user_message}"
        else:
            enhanced_message = user_message

        for attempt in range(max_retries):
            try:
                logger.info(f"Gemini APIå‘¼ã³å‡ºã—è©¦è¡Œ {attempt + 1}/{max_retries}")
                # éåŒæœŸã§Gemini APIã‚’å‘¼ã³å‡ºã—
                loop = asyncio.get_event_loop()
                response = await loop.run_in_executor(None, self._sync_generate, enhanced_message, personality)

                if hasattr(response, "text") and response.text:  # type: ignore
                    response_text = response.text.strip()  # type: ignore
                    if response_text:  # ç©ºã§ãªã„æ–‡å­—åˆ—ã‹ãƒã‚§ãƒƒã‚¯
                        logger.info(
                            f"Gemini APIå¿œç­”æˆåŠŸ: response_length={len(response_text)}, personality={personality.name}"
                        )
                        return response_text, personality

                logger.warning("Gemini APIã‹ã‚‰ç©ºã®å¿œç­”ã‚’å—ä¿¡")
                raise Exception("Empty response from Gemini API")

            except Exception as e:
                # ã‚ˆã‚Šå…·ä½“çš„ãªä¾‹å¤–å‡¦ç†
                error_type = type(e).__name__
                error_message = str(e)

                # 429ã‚¨ãƒ©ãƒ¼ï¼ˆRate Limit Exceededï¼‰ã®ç‰¹åˆ¥å‡¦ç†
                if "429" in error_message or "RESOURCE_EXHAUSTED" in error_message:
                    logger.error(
                        "ğŸš¨ Gemini API Rate Limitè¶…éã‚¨ãƒ©ãƒ¼: æ—¥æ¬¡ã‚¯ã‚©ãƒ¼ã‚¿ï¼ˆ250ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/æ—¥ï¼‰ã‚’è¶…éã—ã¾ã—ãŸã€‚24æ™‚é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã™..."
                    )

                    # ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢
                    sys.exit(1)

                logger.error(
                    f"Gemini APIå‘¼ã³å‡ºã—å¤±æ•— (è©¦è¡Œ {attempt + 1}/{max_retries}): {error_type}: {error_message}"
                )

                if attempt == max_retries - 1:
                    # æœ€å¾Œã®ãƒªãƒˆãƒ©ã‚¤ã§ã‚‚å¤±æ•—ã—ãŸå ´åˆ
                    logger.error("Gemini API: å…¨ãƒªãƒˆãƒ©ã‚¤è©¦è¡ŒãŒå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’è¿”ã™")
                    return self.FALLBACK_MESSAGE, self.system_personality

                # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
                wait_time = 2**attempt
                logger.info(f"Gemini API: {wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
                await asyncio.sleep(wait_time)
                continue

        return self.FALLBACK_MESSAGE, self.system_personality

    def _sync_generate(self, user_message: str, personality: AIPersonality) -> object:
        """åŒæœŸçš„ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆrun_in_executorç”¨ï¼‰.

        æ–°ã—ã„Google Genai APIã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

        Args:
            user_message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            personality: AIäººæ ¼

        Returns:
            Gemini APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

        Raises:
            Exception: APIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ãŸå ´åˆï¼ˆèªè¨¼ã‚¨ãƒ©ãƒ¼ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãªã©ï¼‰

        """
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰max_output_tokensã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ã«ã™ã‚‹ï¼ˆå®‰å…¨ãªå¤‰æ›å‡¦ç†ï¼‰
        try:
            max_tokens = int(os.getenv("AI_MAX_OUTPUT_TOKENS", DEFAULT_MAX_OUTPUT_TOKENS))
        except (ValueError, TypeError):
            logger.warning(
                f"Invalid AI_MAX_OUTPUT_TOKENS value: {os.getenv('AI_MAX_OUTPUT_TOKENS')}. "
                f"Using default: {DEFAULT_MAX_OUTPUT_TOKENS}"
            )
            max_tokens = DEFAULT_MAX_OUTPUT_TOKENS

        response = self.client.models.generate_content(
            model="gemini-2.5-flash-preview-05-20",
            contents=user_message,
            config=types.GenerateContentConfig(  # type: ignore
                system_instruction=personality.prompt_content,
                temperature=0.9,
                max_output_tokens=max_tokens,
            ),
        )
        return response

    def should_respond_to_message(self, message: str) -> bool:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¿œç­”ã™ã¹ãã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹.

        Args:
            message: ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

        Returns:
            å¿œç­”ã™ã¹ãå ´åˆTrue

        """
        # æ—¥æœ¬èªç’°å¢ƒã«å¯¾å¿œã—ãŸ@AIæ¤œå‡ºï¼ˆå…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚‚è€ƒæ…®ï¼‰
        # (?:^|[\sã€€]) - æ–‡é ­ã¾ãŸã¯åŠè§’ãƒ»å…¨è§’ç©ºç™½æ–‡å­—ã®å¾Œ
        # @ai - @aiã®ãƒªãƒ†ãƒ©ãƒ«ï¼ˆå¤§æ–‡å­—å°æ–‡å­—åŒºåˆ¥ãªã—ï¼‰
        # (?=[\sã€€]|$) - åŠè§’ãƒ»å…¨è§’ç©ºç™½æ–‡å­—ã¾ãŸã¯æ–‡æœ«ã®å‰
        pattern = r"(?:^|[\sã€€])@ai(?=[\sã€€]|$)"
        result = bool(re.search(pattern, message.lower()))
        logger.debug(f"@AIæ¤œå‡º: '{message[:50]}...' -> {result}")
        return result


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
gemini_client: GeminiAPIClient | None = None
_lock = threading.Lock()


def get_gemini_client() -> GeminiAPIClient:
    """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—."""
    global gemini_client
    if gemini_client is None:
        with _lock:
            # ãƒ€ãƒ–ãƒ«ãƒã‚§ãƒƒã‚¯ãƒ­ãƒƒã‚­ãƒ³ã‚°
            if gemini_client is None:
                logger.info("æ–°ã—ã„GeminiAPIClientã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ")
                gemini_client = GeminiAPIClient()
    return gemini_client
