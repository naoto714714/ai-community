"""Gemini APIçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«."""

import asyncio
import logging
import os
from pathlib import Path

import google.generativeai as genai  # type: ignore
from google.generativeai.types import GenerateContentResponse  # type: ignore

logger = logging.getLogger(__name__)


class GeminiAPIClient:
    """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ."""

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¸€å…ƒç®¡ç†
    FALLBACK_MESSAGE = "é€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸğŸ˜… ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼"

    def __init__(self) -> None:
        """åˆæœŸåŒ–."""
        logger.info("GeminiAPIClientåˆæœŸåŒ–é–‹å§‹")
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            logger.error("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            raise ValueError("GEMINI_API_KEY environment variable is required")

        logger.info("GEMINI_API_KEYç¢ºèªæ¸ˆã¿")
        genai.configure(api_key=self.api_key)  # type: ignore
        self.model = genai.GenerativeModel("gemini-1.5-flash")  # type: ignore
        logger.info("Gemini 1.5 Flashãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        self._system_prompt: str | None = None
        self._load_system_prompt()

    def _load_system_prompt(self) -> None:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€."""
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰åŸºæœ¬ãƒ‘ã‚¹ã‚’å–å¾—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
        base_path = os.getenv("AI_COMMUNITY_BASE_PATH")
        if base_path:
            prompt_path = Path(base_path) / "prompts" / "001_ãƒãƒ«ãƒˆ.md"
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’æ¨æ¸¬
            prompt_path = Path(__file__).parent.parent.parent.parent / "prompts" / "001_ãƒãƒ«ãƒˆ.md"

        logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿è©¦è¡Œ: {prompt_path}")
        try:
            with open(prompt_path, encoding="utf-8") as f:
                self._system_prompt = f.read()
            logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: æ–‡å­—æ•°={len(self._system_prompt)}")
        except FileNotFoundError:
            logger.warning(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prompt_path}ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨")
            self._system_prompt = """
ã‚ãªãŸã¯ã€Œãƒãƒ«ãƒˆã€ã¨ã„ã†åå‰ã®æ˜ã‚‹ãè¦ªã—ã¿ã‚„ã™ã„ç”·æ€§ã§ã™ã€‚
å¤ªé™½ã®ã‚ˆã†ã«æ¸©ã‹ãã€äººã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¤§åˆ‡ã«ã™ã‚‹æ€§æ ¼ã§ã™ã€‚
è¦ªã—ã¿ã‚„ã™ãã€ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå£èª¿ã§è©±ã—ã¦ãã ã•ã„ã€‚
"""

    async def generate_response(self, user_message: str, max_retries: int = 5) -> str:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹.

        Args:
            user_message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°

        Returns:
            AIã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
        """
        logger.info(f"Gemini APIå¿œç­”ç”Ÿæˆé–‹å§‹: user_message='{user_message[:50]}...' max_retries={max_retries}")
        prompt = f"{self._system_prompt}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_message}\nãƒãƒ«ãƒˆ:"

        for attempt in range(max_retries):
            try:
                logger.info(f"Gemini APIå‘¼ã³å‡ºã—è©¦è¡Œ {attempt + 1}/{max_retries}")
                # éåŒæœŸã§Gemini APIã‚’å‘¼ã³å‡ºã—
                loop = asyncio.get_event_loop()
                response: GenerateContentResponse = await loop.run_in_executor(None, self._sync_generate, prompt)

                if response.text:
                    response_text = response.text.strip()
                    logger.info(f"Gemini APIå¿œç­”æˆåŠŸ: response_length={len(response_text)}")
                    return response_text

                logger.warning("Gemini APIã‹ã‚‰ç©ºã®å¿œç­”ã‚’å—ä¿¡")
                raise Exception("Empty response from Gemini API")

            except Exception as e:
                # ã‚ˆã‚Šå…·ä½“çš„ãªä¾‹å¤–å‡¦ç†
                if "generation" in str(e).lower() or "content" in str(e).lower():
                    logger.error(f"Gemini APIç”Ÿæˆã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{max_retries}): {str(e)}")
                else:
                    logger.error(f"Gemini APIå‘¼ã³å‡ºã—å¤±æ•— (è©¦è¡Œ {attempt + 1}/{max_retries}): {str(e)}")

                if attempt == max_retries - 1:
                    # æœ€å¾Œã®ãƒªãƒˆãƒ©ã‚¤ã§ã‚‚å¤±æ•—ã—ãŸå ´åˆ
                    logger.error("Gemini API: å…¨ãƒªãƒˆãƒ©ã‚¤è©¦è¡ŒãŒå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’è¿”ã™")
                    return self.FALLBACK_MESSAGE

                # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
                wait_time = 2**attempt
                logger.info(f"Gemini API: {wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
                await asyncio.sleep(wait_time)
                continue

        return self.FALLBACK_MESSAGE

    def _sync_generate(self, prompt: str) -> GenerateContentResponse:
        """åŒæœŸçš„ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆrun_in_executorç”¨ï¼‰."""
        return self.model.generate_content(prompt)  # type: ignore

    def should_respond_to_message(self, message: str) -> bool:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¿œç­”ã™ã¹ãã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹.

        Args:
            message: ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

        Returns:
            å¿œç­”ã™ã¹ãå ´åˆTrue
        """
        result = "@ai" in message.lower()
        logger.debug(f"@AIæ¤œå‡º: '{message[:50]}...' -> {result}")
        return result


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
gemini_client: GeminiAPIClient | None = None


def get_gemini_client() -> GeminiAPIClient:
    """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—."""
    global gemini_client
    if gemini_client is None:
        logger.info("æ–°ã—ã„GeminiAPIClientã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ")
        gemini_client = GeminiAPIClient()
    return gemini_client
