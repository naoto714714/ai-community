#!/usr/bin/env python3

import argparse
import json
import logging
import sqlite3
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

logger = logging.getLogger(__name__)


class DatabaseInspector:
    def __init__(self, db_path: str = "chat.db"):
        self.db_path = Path(db_path)
        self.connection: sqlite3.Connection | None = None

    def connect(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶š"""
        try:
            if not self.db_path.exists():
                logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.db_path}")
                return False

            self.connection = sqlite3.connect(self.db_path)
            self.connection.row_factory = sqlite3.Row  # è¾æ›¸å½¢å¼ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
            return True
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def disconnect(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’åˆ‡æ–­"""
        if self.connection:
            self.connection.close()
            self.connection = None

    def get_table_info(self, table_name: str) -> list[dict[str, Any]]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’å–å¾—"""
        if not self.connection:
            return []

        try:
            cursor = self.connection.cursor()
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = cursor.fetchall()

            return [
                {
                    "cid": col["cid"],
                    "name": col["name"],
                    "type": col["type"],
                    "notnull": bool(col["notnull"]),
                    "default_value": col["dflt_value"],
                    "primary_key": bool(col["pk"]),
                }
                for col in columns
            ]
        except Exception as e:
            logger.warning(f"ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼ {table_name}: {e}")
            return []

    def get_table_list(self) -> list[str]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        if not self.connection:
            return []

        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            return [row["name"] for row in cursor.fetchall()]
        except Exception as e:
            logger.warning(f"ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def get_table_data(self, table_name: str, limit: int = 10) -> list[dict[str, Any]]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        if not self.connection:
            return []

        try:
            cursor = self.connection.cursor()
            cursor.execute(f"SELECT * FROM {table_name} LIMIT {limit}")
            return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            logger.warning(f"ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ {table_name}: {e}")
            return []

    def get_table_count(self, table_name: str) -> int:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œæ•°ã‚’å–å¾—"""
        if not self.connection:
            return 0

        try:
            cursor = self.connection.cursor()
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            return cursor.fetchone()[0]
        except Exception as e:
            logger.warning(f"ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œæ•°å–å¾—ã‚¨ãƒ©ãƒ¼ {table_name}: {e}")
            return 0

    def check_data_integrity(self) -> dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        if not self.connection:
            return {}

        results = {"checks": [], "errors": [], "warnings": []}

        try:
            cursor = self.connection.cursor()

            # 1. å¿…é ˆãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
            tables = self.get_table_list()
            required_tables = ["channels", "messages"]

            for table in required_tables:
                if table in tables:
                    results["checks"].append(f"âœ… ãƒ†ãƒ¼ãƒ–ãƒ« '{table}' ãŒå­˜åœ¨ã—ã¾ã™")
                else:
                    results["errors"].append(f"âŒ å¿…é ˆãƒ†ãƒ¼ãƒ–ãƒ« '{table}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            # 2. åˆæœŸãƒãƒ£ãƒ³ãƒãƒ«ã®å­˜åœ¨ç¢ºèª
            if "channels" in tables:
                cursor.execute("SELECT COUNT(*) FROM channels")
                channel_count = cursor.fetchone()[0]

                if channel_count >= 5:
                    results["checks"].append(f"âœ… åˆæœŸãƒãƒ£ãƒ³ãƒãƒ«æ•°: {channel_count}")
                else:
                    results["warnings"].append(f"âš ï¸ ãƒãƒ£ãƒ³ãƒãƒ«æ•°ãŒå°‘ãªã„: {channel_count} (æœŸå¾…å€¤: 5ä»¥ä¸Š)")

                # æœŸå¾…ã•ã‚Œã‚‹ãƒãƒ£ãƒ³ãƒãƒ«åã‚’ãƒã‚§ãƒƒã‚¯
                expected_channels = ["é›‘è«‡", "ã‚²ãƒ¼ãƒ ", "éŸ³æ¥½", "è¶£å‘³", "ãƒ‹ãƒ¥ãƒ¼ã‚¹"]
                cursor.execute("SELECT name FROM channels")
                existing_channels = [row[0] for row in cursor.fetchall()]

                for expected in expected_channels:
                    if expected in existing_channels:
                        results["checks"].append(f"âœ… ãƒãƒ£ãƒ³ãƒãƒ« '{expected}' ãŒå­˜åœ¨ã—ã¾ã™")
                    else:
                        results["warnings"].append(f"âš ï¸ æœŸå¾…ã•ã‚Œã‚‹ãƒãƒ£ãƒ³ãƒãƒ« '{expected}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            # 3. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            if "messages" in tables:
                cursor.execute("SELECT COUNT(*) FROM messages")
                message_count = cursor.fetchone()[0]
                results["checks"].append(f"â„¹ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç·æ•°: {message_count}")

                # ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒã‚§ãƒƒã‚¯
                cursor.execute("SELECT COUNT(*) FROM messages WHERE content = '' OR content IS NULL")
                empty_messages = cursor.fetchone()[0]

                if empty_messages == 0:
                    results["checks"].append("âœ… ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã‚ã‚Šã¾ã›ã‚“")
                else:
                    results["warnings"].append(f"âš ï¸ ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {empty_messages}ä»¶")

                # ç„¡åŠ¹ãªãƒãƒ£ãƒ³ãƒãƒ«IDã‚’ãƒã‚§ãƒƒã‚¯
                cursor.execute("""
                    SELECT COUNT(*) FROM messages
                    WHERE channel_id NOT IN (SELECT id FROM channels)
                """)
                invalid_channel_refs = cursor.fetchone()[0]

                if invalid_channel_refs == 0:
                    results["checks"].append("âœ… å…¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæœ‰åŠ¹ãªãƒãƒ£ãƒ³ãƒãƒ«ã«æ‰€å±ã—ã¦ã„ã¾ã™")
                else:
                    results["errors"].append(f"âŒ ç„¡åŠ¹ãªãƒãƒ£ãƒ³ãƒãƒ«å‚ç…§: {invalid_channel_refs}ä»¶")

            # 4. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            if "messages" in tables:
                cursor.execute("""
                    SELECT COUNT(*) FROM messages
                    WHERE timestamp > datetime('now', '+1 day')
                """)
                future_messages = cursor.fetchone()[0]

                if future_messages == 0:
                    results["checks"].append("âœ… æœªæ¥ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯ã‚ã‚Šã¾ã›ã‚“")
                else:
                    results["warnings"].append(f"âš ï¸ æœªæ¥ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {future_messages}ä»¶")

        except Exception as e:
            results["errors"].append(f"âŒ æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        return results

    def get_statistics(self) -> dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if not self.connection:
            return {}

        stats = {
            "database_file": str(self.db_path),
            "file_size": self.db_path.stat().st_size if self.db_path.exists() else 0,
            "tables": {},
            "generated_at": datetime.now().isoformat(),
        }

        try:
            cursor = self.connection.cursor()
            tables = self.get_table_list()

            for table in tables:
                table_stats = {
                    "row_count": self.get_table_count(table),
                    "columns": self.get_table_info(table),
                    "sample_data": self.get_table_data(table, 3),
                }
                stats["tables"][table] = table_stats

            # è¿½åŠ çµ±è¨ˆæƒ…å ±
            if "messages" in tables:
                # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°
                cursor.execute("""
                    SELECT c.name, COUNT(m.id) as message_count
                    FROM channels c
                    LEFT JOIN messages m ON c.id = m.channel_id
                    GROUP BY c.id, c.name
                    ORDER BY message_count DESC
                """)
                stats["messages_by_channel"] = [{"channel": row[0], "count": row[1]} for row in cursor.fetchall()]

                # æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                cursor.execute("""
                    SELECT user_name, content, timestamp
                    FROM messages
                    ORDER BY created_at DESC
                    LIMIT 5
                """)
                stats["recent_messages"] = [
                    {
                        "user": row[0],
                        "content": row[1][:50] + "..." if len(row[1]) > 50 else row[1],
                        "timestamp": row[2],
                    }
                    for row in cursor.fetchall()
                ]

        except Exception as e:
            stats["error"] = str(e)

        return stats

    def print_schema_report(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›"""
        logger.info("=" * 60)
        logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒãƒ¬ãƒãƒ¼ãƒˆ")
        logger.info("=" * 60)
        logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«: {self.db_path}")

        if self.db_path.exists():
            file_size = self.db_path.stat().st_size
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} ãƒã‚¤ãƒˆ")

        tables = self.get_table_list()
        logger.info(f"ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(tables)}")

        for table in tables:
            logger.info(f"\n--- ãƒ†ãƒ¼ãƒ–ãƒ«: {table} ---")
            columns = self.get_table_info(table)
            row_count = self.get_table_count(table)
            logger.info(f"è¡Œæ•°: {row_count}")
            logger.info("ã‚«ãƒ©ãƒ :")

            for col in columns:
                pk_mark = " (PK)" if col["primary_key"] else ""
                null_mark = " NOT NULL" if col["notnull"] else ""
                default_mark = f" DEFAULT {col['default_value']}" if col["default_value"] else ""
                logger.info(f"  - {col['name']}: {col['type']}{pk_mark}{null_mark}{default_mark}")

    def print_data_report(self, limit: int = 5):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›"""
        logger.info("\n" + "=" * 60)
        logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆ")
        logger.info("=" * 60)

        tables = self.get_table_list()

        for table in tables:
            logger.info(f"\n--- ãƒ†ãƒ¼ãƒ–ãƒ«: {table} ---")
            data = self.get_table_data(table, limit)

            if data:
                logger.info(f"ãƒ‡ãƒ¼ã‚¿ä¾‹ (æœ€æ–°{min(len(data), limit)}ä»¶):")
                for i, row in enumerate(data, 1):
                    logger.info(f"  {i}. {dict(row)}")
            else:
                logger.info("  ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    def print_integrity_report(self):
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›"""
        logger.info("\n" + "=" * 60)
        logger.info("ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆ")
        logger.info("=" * 60)

        integrity = self.check_data_integrity()

        if integrity["checks"]:
            logger.info("âœ… æ­£å¸¸ãƒã‚§ãƒƒã‚¯:")
            for check in integrity["checks"]:
                logger.info(f"  {check}")

        if integrity["warnings"]:
            logger.info("\nâš ï¸ è­¦å‘Š:")
            for warning in integrity["warnings"]:
                logger.info(f"  {warning}")

        if integrity["errors"]:
            logger.info("\nâŒ ã‚¨ãƒ©ãƒ¼:")
            for error in integrity["errors"]:
                logger.info(f"  {error}")

        if not integrity["errors"]:
            logger.info("\nğŸ‰ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ•´åˆæ€§ã«å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logging.basicConfig(level=logging.INFO, format="%(message)s")
    parser = argparse.ArgumentParser(description="AI Community Backend ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œæŸ»ãƒ„ãƒ¼ãƒ«")
    parser.add_argument("--db", default="chat.db", help="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--output", help="çµ±è¨ˆæƒ…å ±ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆJSONå½¢å¼ï¼‰")
    parser.add_argument("--limit", type=int, default=5, help="ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºä»¶æ•°ã®åˆ¶é™")
    parser.add_argument("--schema-only", action="store_true", help="ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã®ã¿è¡¨ç¤º")

    args = parser.parse_args()

    inspector = DatabaseInspector(args.db)

    if not inspector.connect():
        sys.exit(1)

    try:
        # ã‚¹ã‚­ãƒ¼ãƒãƒ¬ãƒãƒ¼ãƒˆ
        inspector.print_schema_report()

        if not args.schema_only:
            # ãƒ‡ãƒ¼ã‚¿ãƒ¬ãƒãƒ¼ãƒˆ
            inspector.print_data_report(args.limit)

            # æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆ
            inspector.print_integrity_report()

        # çµ±è¨ˆæƒ…å ±ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›
        if args.output:
            stats = inspector.get_statistics()
            output_file = Path(args.output)
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(stats, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"\nğŸ“„ çµ±è¨ˆæƒ…å ±ã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")

    finally:
        inspector.disconnect()


if __name__ == "__main__":
    main()
